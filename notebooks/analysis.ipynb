{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naslib.utils.io import read_json\n",
    "from pathlib import Path \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.axes import Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "rcParams['axes.titlepad'] = 15\n",
    "rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"CIFAR10\" , \"CIFAR100\", \"ImageNet16-120\"]\n",
    "home = Path.home() / \"Desktop/Experiments\"\n",
    "\n",
    "def get_label_and_path(dataset): \n",
    "    if \"CIFAR\" in dataset:\n",
    "        dataset = dataset.lower()\n",
    "    exp_0 = home/\"acq_search=mutation/nasbench201\" / dataset / \"acq=its/num_to_mutate=2/num_init=10/bananas__ensemble_mlp__gaussian__num_quantiles=10\"\n",
    "    exp_1 = home/\"acq_search=mutation/nasbench201\" / dataset  / \"acq=its/num_to_mutate=2/num_init=10/bananas__ensemble_mlp__CP_split__train_cal_split=05__num_quantiles=10\"\n",
    "    exp_2 = home/\"acq_search=mutation/nasbench201\" / dataset  / \"acq=its/num_to_mutate=2/num_init=10/bananas__ensemble_mlp__CP_cv__train_cal_split=3__num_quantiles=10\"\n",
    "    exp_3 = home/\"acq_search=mutation/nasbench201\" / dataset  / \"acq=its/num_to_mutate=2/num_init=10/bananas__ensemble_mlp__CP_bootstrap__num_ensemble=5__num_quantiles=10_absresidual\"\n",
    "    exp_4 = home/\"acq_search=mutation/nasbench201\" / dataset  / \"acq=its/num_to_mutate=2/num_init=10/bananas__quantile__CP_split__train_cal_split=05__num_quantiles=10\"\n",
    "    exp_5 = home/\"acq_search=mutation/nasbench201\" / dataset  / \"acq=ei/num_to_mutate=2/num_init=10/bananas__quantile__CP_cv__train_cal_split=3__num_quantiles=10\"\n",
    "\n",
    "    label_and_path = {\n",
    "        \"BANANAS\": exp_0,\n",
    "        \"SCP Ensemble\": exp_1,\n",
    "        \"CrossVal-CP Ensemble\": exp_2,\n",
    "        \"Bootstrap-CP Ensemble\": exp_3,\n",
    "        \"SCP Quantile\": exp_4,\n",
    "        \"CrossVal-CP Quantile\": exp_5,\n",
    "    }\n",
    "    return label_and_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_VAL_ACC = \"valid_acc\"\n",
    "QUERY_CAL_ERR = \"calibration_score\" \n",
    "LOG_FILENAME = \"errors.json\"\n",
    "\n",
    "def collect_json_info_all_seeds(folder: Path, filename: str = LOG_FILENAME, query_key: str = QUERY_CAL_ERR):\n",
    "    matches = list(folder.rglob(pattern=f\"./seed=*\"))\n",
    "\n",
    "    scores={}\n",
    "    for p in matches:\n",
    "        scores[p.name] = read_json(p / filename)[query_key]\n",
    "    df = pd.DataFrame(scores)\n",
    "    df.index += 1   # python indexing starts from 0\n",
    "    df.index.name = \"epochs\"\n",
    "    return df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation accuracy and RMSCE per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_json_single_experiment(path: Path, ax: Axes, label: str | None, query_key: str, ylabel: str, start_epoch=0, dahses = None):\n",
    "    df_wide = collect_json_info_all_seeds(folder=path, query_key=query_key)     \n",
    "    mean = df_wide.iloc[-1, :].mean()\n",
    "    std = df_wide.iloc[-1, :].std()\n",
    "\n",
    "    df_wide = df_wide.reset_index()    \n",
    "    df_wide = df_wide[df_wide[\"epochs\"] >= start_epoch]\n",
    "    df_long = pd.melt(df_wide, id_vars='epochs')\n",
    "    legend = None if label is None else \"auto\"\n",
    "\n",
    "    label = f\"{label}:  mean={round(mean, 3)}, std={round(std, 4)}\"\n",
    "    sns.lineplot(x=\"epochs\", data=df_long, y=\"value\", err_style=\"band\", errorbar=\"sd\", label=label, ax=ax, legend=legend, alpha=0.8, dashes=dahses)\n",
    "    ax.set_xlabel(\"epochs\")\n",
    "    ax.set_ylabel(ylabel=ylabel)\n",
    "    ax.tick_params(labelbottom=True)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_set = [\n",
    "    \"#377EB8\",  # blue\n",
    "    \"#4DAF4A\",  # green\n",
    "    \"#FF7F00\",  # orange\n",
    "    \"#984EA3\",  # purple\n",
    "    \"#E41A1C\",  # red\n",
    "  #  \"#FFD92F\",  # yellow\n",
    " #   \"#00CED1\",  # cyan/turquois\n",
    "]\n",
    "\n",
    "# Set as default cycle\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=color_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(ncols=1, nrows=1, figsize=(8, 5))\n",
    "# start_epoch = 10\n",
    "# label_and_path = get_label_and_path(dataset=\"cifar10\")\n",
    "# for label, path in label_and_path.items():\n",
    "#     plot_json_single_experiment(path=path, ax=axes, label=label, query_key=QUERY_VAL_ACC, ylabel=\"validation accuracy\", start_epoch=start_epoch)   \n",
    "#     axes.legend(loc=\"lower right\")\n",
    "\n",
    "#     axes.set_title(\"CIFAR10\", y=0, pad=-55, verticalalignment=\"top\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(15, 7),sharex=True, gridspec_kw={\"height_ratios\" : [1.5, 2.5]})\n",
    "start_epoch = 10\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    label_and_path = get_label_and_path(dataset=dataset)\n",
    "    for label, path in label_and_path.items():\n",
    "        plot_json_single_experiment(path=path, ax=axes[0, i], label=None, query_key=QUERY_CAL_ERR, ylabel=\"rmsce\", start_epoch=start_epoch)\n",
    "        plot_json_single_experiment(path=path, ax=axes[1, i], label=label, query_key=QUERY_VAL_ACC, ylabel=\"validation accuracy\", start_epoch=start_epoch)\n",
    "        axes[1, i].legend(loc=\"lower right\")\n",
    "        axes[1, i].set_title(dataset, y=0, pad=-55, verticalalignment=\"top\", fontsize=12)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Errors for Ensemble Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from naslib.optimizers.bananas.calibration_utils import ConditionalEstimation\n",
    "\n",
    "def get_ensmeble_mlp_pred_abs_errors(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        _, obs_and_dist = pickle.load(f)\n",
    "        obs_and_dist_unpacked = list(zip(*obs_and_dist))\n",
    "        y_true = list(obs_and_dist_unpacked[0])\n",
    "        y_pred = [np.mean(item.point_prediction) if isinstance(item, ConditionalEstimation) else np.nan for item in obs_and_dist_unpacked[1]]\n",
    "        return  abs(np.array(y_pred) - np.array(y_true))\n",
    "    \n",
    "def collect_preds_all_seeds(folder: Path):\n",
    "    matches = list(folder.rglob(pattern=f\"./seed=*\"))\n",
    "    errors ={}\n",
    "    for p in matches:\n",
    "        errors[p.name] = get_ensmeble_mlp_pred_abs_errors(path=p / \"search_log.pt\")\n",
    "    df = pd.DataFrame(errors)\n",
    "    df.index += 1   # python indexing starts from 0\n",
    "    df.index.name = \"epochs\"\n",
    "    return df.sort_index(axis=1)\n",
    "\n",
    "\n",
    "def plot_preds_single_experiment(path: Path, ax: Axes, label: str | None, ylabel: str, start_epoch=0, smooth_window=1):\n",
    "    df_wide = collect_preds_all_seeds(folder=path)\n",
    "    mean = np.nanmean(df_wide.values)\n",
    "    std = np.nanstd(df_wide.values)\n",
    "\n",
    "    df_wide = df_wide.reset_index()    \n",
    "    df_wide = df_wide[df_wide[\"epochs\"] >= start_epoch].rolling(10).mean()\n",
    "    df_long = pd.melt(df_wide, id_vars='epochs')\n",
    "    legend = None if label is None else \"auto\"\n",
    "\n",
    "    label = f\"{label}: mean={round(mean, 3)}, std={round(std, 4)}\"\n",
    "    sns.lineplot(x=\"epochs\", data=df_long, y=\"value\", err_style=\"band\", errorbar=\"sd\", label=label, ax=ax, legend=legend, alpha=0.8)\n",
    "    ax.set_xlabel(\"epochs\")\n",
    "    ax.set_ylabel(ylabel=ylabel)\n",
    "    ax.tick_params(labelbottom=True)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(15, 4))\n",
    "start_epoch = 0\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    label_and_path = get_label_and_path(dataset=dataset)\n",
    "    for label, path in label_and_path.items():\n",
    "        plot_preds_single_experiment(path=path, ax=axes[i], label=label, ylabel=\"absolute prediction error\",  start_epoch=start_epoch)\n",
    "        axes[i].set_title(dataset, y=0, pad=-45, verticalalignment=\"top\", fontsize=12)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_outputs = {}\n",
    "# for i, dataset in enumerate(datasets):\n",
    "#     label_and_path = get_label_and_path(dataset=dataset)\n",
    "#     for label, path in label_and_path.items():\n",
    "#         corr_outputs.setdefault(label, pd.DataFrame())\n",
    "         \n",
    "#         series = collect_json_info_all_seeds(folder=path, query_key=QUERY_VAL_ACC).iloc[-1, :]\n",
    "#         df = corr_outputs[label]\n",
    "#         df[dataset] = series\n",
    "#         corr_outputs[label] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(15, 10), constrained_layout=True)\n",
    "# fig.subplots_adjust(wspace=0.45, hspace=0.3)\n",
    "\n",
    "# corr_matrices = []\n",
    "# for i, (name, data) in enumerate(corr_outputs.items()):\n",
    "#     corrlation = data.corr()\n",
    "#     corr_matrices.append(corrlation)\n",
    "\n",
    "#     row_idx = i // 3\n",
    "#     col_idx = i % 3\n",
    "#     ax = axes[row_idx, col_idx]\n",
    "#     sns.heatmap(corrlation, annot=True, ax=ax, square=True, cbar=False)\n",
    "#     ax.set_title(name, y=0, pad=-40, verticalalignment=\"top\", fontsize=12)\n",
    "#     ax.set_xticklabels(ax.get_xticklabels(), rotation=0, ha='center', fontsize=9.5)  # X-axis: slanted or horizontal\n",
    "#     ax.set_yticklabels(ax.get_yticklabels(), rotation=90, va='center', fontsize=9.5)  # Y-axis: vertical\n",
    "\n",
    "\n",
    "# # add color bar\n",
    "# cbar_ax = fig.add_axes([0.95, 0.15, 0.015, 0.7])  # [left, bottom, width, height]\n",
    "# sns.heatmap(data.corr(), cbar_ax=cbar_ax, cbar=True)\n",
    "# cbar_ax.clear()  # remove the dummy heatmap\n",
    "# cb = fig.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin=-0.5, vmax=0.5)), cax=cbar_ax)\n",
    "# cb.set_label('Correlation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_outputs = {}\n",
    "for i, dataset in enumerate(datasets):\n",
    "    label_and_path = get_label_and_path(dataset=dataset)\n",
    "    for label, path in label_and_path.items():\n",
    "        series = collect_json_info_all_seeds(folder=path, query_key=QUERY_VAL_ACC).iloc[-1, :]\n",
    "        corr_outputs[f\"{dataset}_{label}\"] = series\n",
    "\n",
    "corr_df = pd.concat(corr_outputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "\n",
    "def transparent_cmap(cmap_name=\"coolwarm\", alpha=0.6):\n",
    "    base = cm.get_cmap(cmap_name)\n",
    "    colors = base(np.linspace(0, 1, 256))\n",
    "    colors[:, -1] = alpha  # set the alpha channel\n",
    "    return ListedColormap(colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=1, nrows=1, figsize=(15, 10), constrained_layout=True)\n",
    "mask = np.triu(np.ones_like(corr_df.corr(), dtype=bool))\n",
    "norm = plt.Normalize(vmin=-0.3, vmax=0.3)\n",
    "cmap =  transparent_cmap('RdBu_r', alpha=0.9)\t\n",
    "sns.heatmap(corr_df.corr(), cbar=False,  annot=True, square=True, mask=mask, norm=norm, cmap=cmap, annot_kws={\"size\": 9})\n",
    "\n",
    "cbar_ax = fig.add_axes([0.8, 0.3, 0.02, 0.6])  # [left, bottom, width, height]\n",
    "sns.heatmap(corr_df.corr(), cbar_ax=cbar_ax, cbar=True)\n",
    "cbar_ax.clear()  # remove the dummy heatmap\n",
    "cb = fig.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for i, dataset in enumerate(datasets):\n",
    "    label_and_path = get_label_and_path(dataset=dataset)\n",
    "    df = pd.DataFrame(index=label_and_path.keys())\n",
    "    for label, path in label_and_path.items():\n",
    "        val_acc = collect_json_info_all_seeds(folder=path, query_key=QUERY_VAL_ACC).iloc[-1,:]\n",
    "        cal_err = collect_json_info_all_seeds(folder=path, query_key=QUERY_CAL_ERR).iloc[-1,:]\n",
    "        df.loc[label, \"val. acc\"] = f\"{round(val_acc.mean(), 3)} ({round(val_acc.std(), 4)})\"\n",
    "        df.loc[label, \"RMSCE\"] = f\"{round(cal_err.mean(), 3)} ({round(cal_err.std(), 4)})\"\n",
    "        dfs[dataset] =  df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation of Estimated Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from naslib.optimizers.bananas.distribution import GaussianDist, PointwiseInterpolatedDist\n",
    "from naslib.optimizers.bananas.calibration_utils import ConditionalEstimation\n",
    "\n",
    "def get_distribution_std(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        _, obs_and_dist = pickle.load(f)\n",
    "        obs_and_dist_unpacked = list(zip(*obs_and_dist))\n",
    "        stds = []\n",
    "        for item in obs_and_dist_unpacked[1]:\n",
    "            if isinstance(item, ConditionalEstimation):\n",
    "                if isinstance(item.distribution, GaussianDist):\n",
    "                    std = item.distribution.dist.std()\n",
    "                elif isinstance(item.distribution, PointwiseInterpolatedDist):\n",
    "                    std = item.distribution.std()\n",
    "            else:\n",
    "                std = np.nan\n",
    "            stds.append(std)\n",
    "        return pd.Series(stds)\n",
    "    \n",
    "\n",
    "def collect_dist_stds_all_seeds(folder: Path):\n",
    "    matches = list(folder.rglob(pattern=f\"./seed=*\"))\n",
    "    stds ={}\n",
    "    for p in matches:\n",
    "        stds[p.name] = get_distribution_std(path=p / \"search_log.pt\")\n",
    "    df = pd.DataFrame(stds)\n",
    "    df.index += 1   # python indexing starts from 0\n",
    "    df.index.name = \"epochs\"\n",
    "    return df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    label_and_path = get_label_and_path(dataset=dataset)\n",
    "\n",
    "    dfs_stds = {}\n",
    "    for label, path in label_and_path.items():\n",
    "        dfs_stds[label] = collect_dist_stds_all_seeds(folder=path)\n",
    "    all_data[dataset] = dfs_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=5, figsize=(15, 22) )\n",
    "epochs = [20, 50, 80, 110, 140]\n",
    "\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    dfs_stds =  all_data[dataset]\n",
    "    for j, epoch in enumerate(epochs):\n",
    "        dfs_tmp = {}\n",
    "        for label, df in dfs_stds.items():\n",
    "            dfs_tmp[label] = df.loc[epoch + 1]\n",
    "\n",
    "        df_ =  pd.concat(dfs_tmp, axis=1)\n",
    "        ax = axes[j, i]\n",
    "        if j > 0:\n",
    "            ax.sharex(axes[0, i])\n",
    "        \n",
    "        sns.boxplot(df_, ax=ax, linecolor=\"#137\", linewidth=.7,  boxprops={\"facecolor\": (.3, .5, .7)}, orient=\"h\", medianprops={\"color\": \"black\", \"linewidth\": 0.7})\n",
    "        for label in ax.get_yticklabels():\n",
    "           label.set_rotation(45)\n",
    "           label.set_fontsize(10)\n",
    "        ax.tick_params(labelbottom=True) \n",
    "        ax.set_title(f\"distribution std ({epoch}-th epoch)\", y=0, pad=-20, verticalalignment=\"top\", fontsize=10)\n",
    "    ax.set_xlabel(dataset, labelpad=35)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas_cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
